{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pylab as plt\n",
    "import json\n",
    "import torch\n",
    "import torchvision\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import tensorrt as trt\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.ERROR)\n",
    "trt.init_libnvinfer_plugins(TRT_LOGGER, '')\n",
    "import common\n",
    "import onnxruntime\n",
    "onnxruntime.disable_telemetry_events()\n",
    "from dalle import TextTokenizer\n",
    "from utils_sr import *\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from dalle import VQGanDetokenizer\n",
    "\n",
    "detokenizer = VQGanDetokenizer().eval()\n",
    "detokenizer.load_state_dict(torch.load('models/detoker.pt'))\n",
    "\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem):\n",
    "        self.host = host_mem\n",
    "        self.device = cuda.mem_alloc(host_mem.nbytes)\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    if isinstance(tensor, numpy.ndarray):\n",
    "        return tensor\n",
    "    else:\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "def get_engine_info(engine0):\n",
    "    for b in engine0:\n",
    "        print(b, trt.nptype(engine0.get_binding_dtype(b)), trt.volume(engine0.get_binding_shape(b)) * engine0.max_batch_size)\n",
    "\n",
    "runtime = trt.Runtime(TRT_LOGGER)\n",
    "stream = cuda.Stream()\n",
    "with open(\"engines/decoder0v2.trt32\", mode=\"rb\") as f:\n",
    "    engine0 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context0 = engine0.create_execution_context()\n",
    "with open(\"engines/decoder1v2.trt\", mode=\"rb\") as f:\n",
    "    engine1 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context1 = engine1.create_execution_context()\n",
    "with open(\"engines/decoder2v2.trt\", mode=\"rb\") as f:\n",
    "    engine2 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context2 = engine2.create_execution_context()\n",
    "with open(\"engines/decoder3v2.trt\", mode=\"rb\") as f:\n",
    "    engine3 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context3 = engine3.create_execution_context()\n",
    "image_count = 1\n",
    "tAM = HostDeviceMem(cuda.pagelocked_empty(128 * image_count, numpy.int32))\n",
    "tES = HostDeviceMem(cuda.pagelocked_empty(262144 * image_count, numpy.float32))\n",
    "tIT = HostDeviceMem(cuda.pagelocked_empty(1 * image_count, numpy.int32))\n",
    "tTI = HostDeviceMem(cuda.pagelocked_empty(1, numpy.int32))\n",
    "tDS = HostDeviceMem(cuda.pagelocked_empty(4096 * image_count, numpy.float32))\n",
    "tOut = HostDeviceMem(cuda.pagelocked_empty(32832 * image_count, numpy.float32))\n",
    "tAS0 = HostDeviceMem(cuda.pagelocked_empty(12582912 * image_count, numpy.float32))\n",
    "tAS1 = HostDeviceMem(cuda.pagelocked_empty(12582912 * image_count, numpy.float32))\n",
    "tAS2 = HostDeviceMem(cuda.pagelocked_empty(12582912 * image_count, numpy.float32))\n",
    "tAS3 = HostDeviceMem(cuda.pagelocked_empty(12582912 * image_count, numpy.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = \"night beautiful norway fjord with blue river\"\n",
    "TEMPERATURE = 1.0\n",
    "TOPK = 2048\n",
    "TOPP = 0.1\n",
    "SFACTOR = 32\n",
    "SEED = 0\n",
    "WIDTH = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "numpy.random.seed(42)\n",
    "\n",
    "with open('models/vocab.json', 'r', encoding='utf8') as f:\n",
    "    vocab = json.load(f)\n",
    "with open('models/merges.txt', 'r', encoding='utf8') as f:\n",
    "    merges = f.read().split(\"\\n\")[1:-1]\n",
    "ort_session0 = onnxruntime.InferenceSession('./onnx/encoder0/encoder0.onnx', providers=['CPUExecutionProvider'])\n",
    "ort_session1 = onnxruntime.InferenceSession('./onnx/encoder1/encoder1.onnx', providers=['CPUExecutionProvider'])\n",
    "tokenizer = TextTokenizer(vocab, merges)\n",
    "WINDOW = list(range(256))\n",
    "tokens = tokenizer.tokenize(TEXT, is_verbose=False)[:64]\n",
    "text_tokens = numpy.ones((2, 64), dtype=numpy.int32)\n",
    "text_tokens[0, :2] = [tokens[0], tokens[-1]]\n",
    "text_tokens[1, :len(tokens)] = tokens\n",
    "text_tokens = torch.tensor(\n",
    "    text_tokens, \n",
    "    dtype=torch.long, \n",
    ")\n",
    "ort_inputs = {ort_session0.get_inputs()[0].name: to_numpy(text_tokens)}\n",
    "ort_outs = ort_session0.run(None, ort_inputs)\n",
    "ort_inputs = {ort_session1.get_inputs()[0].name: to_numpy(ort_outs[0]), ort_session1.get_inputs()[1].name: to_numpy(text_tokens)}\n",
    "ort_outs = ort_session1.run(None, ort_inputs)\n",
    "encoder_state = torch.from_numpy(ort_outs[0])\n",
    "seed_add = 0\n",
    "expanded_indices = [0] * image_count + [1] * image_count\n",
    "text_tokens = text_tokens[expanded_indices]\n",
    "encoder_state = encoder_state[expanded_indices]\n",
    "attention_mask = text_tokens.not_equal(1).long()\n",
    "attention_state = torch.zeros(size=(24, image_count * 4, 256, 2048))\n",
    "image_tokens = torch.full((WIDTH + 1, image_count), 16415, dtype=torch.long)\n",
    "if SEED > 0: torch.manual_seed(SEED + seed_add)\n",
    "token_indices = torch.arange(256).repeat(WIDTH // 256)\n",
    "settings = torch.tensor([TEMPERATURE, TOPK, SFACTOR])\n",
    "numpy.copyto(tAM.host, to_numpy(attention_mask).ravel())\n",
    "numpy.copyto(tES.host, to_numpy(encoder_state).ravel())\n",
    "numpy.copyto(tAS0.host, to_numpy(attention_state[:6]).ravel())\n",
    "numpy.copyto(tAS1.host, to_numpy(attention_state[6:12]).ravel())\n",
    "numpy.copyto(tAS2.host, to_numpy(attention_state[12:18]).ravel())\n",
    "numpy.copyto(tAS3.host, to_numpy(attention_state[18:]).ravel())\n",
    "cuda.memcpy_htod_async(tAM.device, tAM.host, stream)\n",
    "cuda.memcpy_htod_async(tES.device, tES.host, stream)\n",
    "cuda.memcpy_htod_async(tAS0.device, tAS0.host, stream)\n",
    "cuda.memcpy_htod_async(tAS1.device, tAS1.host, stream)\n",
    "cuda.memcpy_htod_async(tAS2.device, tAS2.host, stream)\n",
    "cuda.memcpy_htod_async(tAS3.device, tAS3.host, stream)\n",
    "total_logits = torch.zeros((WIDTH, 2, 16384)).float()\n",
    "for i in tqdm(range(WIDTH)):\n",
    "    numpy.copyto(tIT.host, to_numpy(image_tokens[i]).ravel())\n",
    "    numpy.copyto(tTI.host, to_numpy(token_indices[[i]]).ravel())\n",
    "    cuda.memcpy_htod_async(tIT.device, tIT.host, stream)\n",
    "    cuda.memcpy_htod_async(tTI.device, tTI.host, stream)\n",
    "    queue = [tAM, tES, tAS0, tIT, tTI, tDS, tAS0]\n",
    "    context0.execute_async_v2(bindings=[v.device for v in queue], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    queue = [tAM, tES, tDS, tAS1, tTI, tDS, tAS1]\n",
    "    context1.execute_async_v2(bindings=[v.device for v in queue], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    queue = [tAM, tES, tDS, tAS2, tTI, tDS, tAS2]\n",
    "    context2.execute_async_v2(bindings=[v.device for v in queue], stream_handle=stream.handle)\n",
    "    stream.synchronize()\n",
    "    queue = [tAM, tES, tDS, tAS3, tTI, tAS3, tOut]\n",
    "    context3.execute_async_v2(bindings=[v.device for v in queue], stream_handle=stream.handle)\n",
    "    cuda.memcpy_dtoh_async(tOut.host, tOut.device, stream)\n",
    "    stream.synchronize()\n",
    "    logits = torch.from_numpy(tOut.host).reshape(2, 1, 16416)\n",
    "    logits = logits[:, -1, : 2 ** 14]\n",
    "    total_logits[i] = logits\n",
    "    temperature = settings[[0]]\n",
    "    top_k = settings[[1]].to(torch.long)\n",
    "    supercondition_factor = settings[[2]]\n",
    "    logits = logits[:image_count] * (1 - supercondition_factor) + logits[image_count:] * supercondition_factor\n",
    "    logits = logits[0]\n",
    "    _, pindices = logits.topk(logits.shape[0] - TOPK, largest=False)\n",
    "    probas = logits.softmax(-1)\n",
    "    min_val = min(probas.max().item(), TOPP)\n",
    "    logits[pindices] = 0\n",
    "    logits[probas < min_val] = 0\n",
    "    image_tokens[i + 1] = torch.multinomial(logits.softmax(-1), 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast(dtype=torch.float32) and torch.no_grad():\n",
    "    z = image_tokens[1:].T.reshape(-1, 256).clone()\n",
    "    z.clamp_(0, detokenizer.vocab_count - 1)\n",
    "    # z = z.repeat(1,1,2)\n",
    "    z = z.view([-1, 1, 2 ** 4, 2 ** 4])\n",
    "    z = z.flatten(1, 2).transpose(1, 0).flatten(1, 2)\n",
    "    z = z.flatten().unsqueeze(1)\n",
    "    z = detokenizer.embedding.forward(z)\n",
    "    z = z.view((1, 16, -1, 2 ** 8))\n",
    "    z = torch.cat([z[:,:,:16], z[:,:,16:]], dim=2)\n",
    "    z = torch.cat([z[:,:,:16], z[:,:,16:].flip(2)], dim=2)\n",
    "    # z = z.roll(8, 2)\n",
    "    t1 = z.shape[1]; t2 = z.shape[2]\n",
    "    z = z.permute(0, 3, 1, 2).contiguous()\n",
    "    z = detokenizer.post_quant_conv.forward(z)\n",
    "    z = detokenizer.decoder.conv_in.forward(z)\n",
    "    z = detokenizer.decoder.mid.forward(z, t1, t2)\n",
    "    for i in range(4, -1, -1):\n",
    "        z = detokenizer.decoder.up[i].forward(z, t1, t2)\n",
    "    z = detokenizer.decoder.norm_out.forward(z)\n",
    "    z *= torch.sigmoid(z)\n",
    "    z = detokenizer.decoder.conv_out.forward(z)\n",
    "    z = z.permute(0, 2, 3, 1)\n",
    "    images = (z.clip(0.0, 1.0) * 255).cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray((images[0].numpy()).astype(numpy.uint8))\n",
    "img.save('output.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del engine0, engine1, engine2, context0, context1, context2, stream\n",
    "stream = cuda.Stream()\n",
    "with open(f\"engines/esrgan1x1.trt\", mode=\"rb\") as f:\n",
    "    engine3 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context3 = engine3.create_execution_context()\n",
    "inputs, outputs, bindings = common.allocate_buffers(engine3)\n",
    "lr_image = Image.open('output.png').convert('RGB')\n",
    "lr_image = np.array(lr_image)\n",
    "lr_image = pad_reflect(lr_image, 15)\n",
    "patches, p_shape = split_image_into_overlapping_patches(lr_image, patch_size=192, padding_size=24)\n",
    "patches = np.swapaxes(np.swapaxes(patches, 1, 2), 1, 3)\n",
    "numpy.copyto(inputs[0].host, patches.ravel() / 255.)\n",
    "res = common.do_inference(context3, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)[0]\n",
    "np_sr_image = res.reshape(-1, 1920, 1920, 3)\n",
    "padded_size_scaled = tuple(np.multiply(p_shape[0:2], 8)) + (3,)\n",
    "scaled_image_shape = tuple(np.multiply(lr_image.shape[0:2], 8)) + (3,)\n",
    "np_sr_image = stich_together(np_sr_image, padded_image_shape=padded_size_scaled, target_shape=scaled_image_shape, padding_size=24 * 8)\n",
    "sr_img = (np_sr_image*255).astype(np.uint8)\n",
    "sr_img = unpad_image(sr_img, 15*8)\n",
    "sr_img = Image.fromarray(sr_img)\n",
    "sr_img.save('sr_output.png')\n",
    "sr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del engine0, engine1, engine2, context0, context1, context2, stream\n",
    "stream = cuda.Stream()\n",
    "with open(f\"engines/srgan1x1.trt\", mode=\"rb\") as f:\n",
    "    engine3 = runtime.deserialize_cuda_engine(f.read())\n",
    "    context3 = engine3.create_execution_context()\n",
    "inputs, outputs, bindings = common.allocate_buffers(engine3)\n",
    "lr_image = Image.open('output.png').convert('RGB')\n",
    "lr_image = np.array(lr_image)\n",
    "numpy.copyto(inputs[0].host, numpy.moveaxis(lr_image[None], -1, 1).ravel() / 255.)\n",
    "res = common.do_inference(context3, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)[0]\n",
    "# np_sr_image = numpy.swapaxes(res.reshape(3, 256*4, 256*4), 0, -1)\n",
    "np_sr_image = numpy.moveaxis(res.reshape(3, 256*4, -1), 0, -1).clip(0, 1)\n",
    "sr_img = (np_sr_image*255).astype(np.uint8)\n",
    "sr_img = Image.fromarray(sr_img)\n",
    "sr_img.save('sr_output.png')\n",
    "sr_img"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
