# Text to image inference with TensorRT

This repository contains scripts for creating TensorRT engines and notebooks for running the [mini-dalle model](https://github.com/kuprel/min-dalle). Inference on TensorRT allows times faster inference on GPUs without Tensor Cores support.