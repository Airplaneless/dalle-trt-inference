{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy\n",
    "import torch\n",
    "import torch_tensorrt\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from dalle import VQGanDetokenizer, TextTokenizer\n",
    "torch_tensorrt.logging.set_reportable_log_level(torch_tensorrt.logging.Level.Error)\n",
    "\n",
    "with open('models/vocab.json', 'r', encoding='utf8') as f:\n",
    "    vocab = json.load(f)\n",
    "with open('models/merges.txt', 'r', encoding='utf8') as f:\n",
    "    merges = f.read().split(\"\\n\")[1:-1]\n",
    "tokenizer = TextTokenizer(vocab, merges)\n",
    "image_count = 4\n",
    "\n",
    "trt_encoder0 = torch.jit.load(\"/dev/shm/encoder0.ts\")\n",
    "trt_encoder1 = torch.jit.load(\"/dev/shm/encoder1.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 803, 1775, 91, 7134, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = 4\n",
    "tokens = tokenizer.tokenize('cat face in sunglasses', is_verbose=False)[:64]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokens = numpy.ones((2, 64), dtype=numpy.int32)\n",
    "text_tokens[0, :2] = [tokens[0], tokens[-1]]\n",
    "text_tokens[1, :len(tokens)] = tokens\n",
    "text_tokens = torch.tensor(\n",
    "    text_tokens, \n",
    "    dtype=torch.int32, \n",
    "    device='cuda'\n",
    ")\n",
    "attention_mask = text_tokens.not_equal(1).half()\n",
    "\n",
    "encoder_state = trt_encoder0(text_tokens.to(torch.int32), attention_mask)\n",
    "encoder_state = trt_encoder1(encoder_state.half(), attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trt_encoder0\n",
    "del trt_encoder1\n",
    "# trt_decoder0 = torch.jit.load(\"decoder0.ts\")\n",
    "# trt_decoder1 = torch.jit.load(\"decoder1.ts\")\n",
    "# trt_decoder2 = torch.jit.load(\"decoder2.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_indices = [0] * image_count + [1] * image_count\n",
    "text_tokens = text_tokens[expanded_indices]\n",
    "encoder_state = encoder_state[expanded_indices].half()\n",
    "attention_mask = text_tokens.not_equal(1).half()\n",
    "attention_state = torch.zeros(size=(24, image_count * 4, 256, 2048)).half().cuda()\n",
    "image_tokens = torch.full((256 + 1, image_count), 16415, dtype=torch.int32, device='cuda')\n",
    "torch.manual_seed(0)\n",
    "token_indices = torch.arange(256, dtype=torch.int32, device='cuda')\n",
    "settings = torch.tensor([1.0, 256, 16.0], dtype=torch.float32, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "torch.cuda.empty_cache()\n",
    "token_index_batched = token_indices[[i]][[0] * image_count * 2]\n",
    "prev_tokens = image_tokens[i][list(range(image_count)) * 2]\n",
    "prev_tokens.clamp_(0, 16415)\n",
    "token_mask = torch.zeros(16, 256, 2048, dtype=torch.float16, device='cuda')\n",
    "token_mask[:, token_index_batched[0]] = 1\n",
    "token_indices = torch.arange(-1, 255, dtype=torch.int32, device='cuda')\n",
    "self_attn_mask = (token_indices < token_index_batched[0][None]).half().cuda()\n",
    "self_attn_mask = self_attn_mask.repeat(encoder_state.shape[0],1)\n",
    "trt_decoder0 = torch.jit.load(\"/dev/shm/decoder0.ts\")\n",
    "decoder_state, attention_state = trt_decoder0(attention_mask, encoder_state, attention_state, prev_tokens, token_index_batched, token_mask, self_attn_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/256 [00:02<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(256)):\n",
    "    torch.cuda.empty_cache()\n",
    "    token_index_batched = token_indices[[i]][[0] * image_count * 2]\n",
    "    prev_tokens = image_tokens[i][list(range(image_count)) * 2]\n",
    "    prev_tokens.clamp_(0, 16415)\n",
    "    token_mask = torch.zeros(16, 256, 2048, dtype=torch.float16, device='cuda')\n",
    "    token_mask[:, token_index_batched[0]] = 1\n",
    "    token_indices = torch.arange(-1, 255, dtype=torch.int32, device='cuda')\n",
    "    self_attn_mask = (token_indices < token_index_batched[0][None]).half().cuda()\n",
    "    self_attn_mask = self_attn_mask.repeat(encoder_state.shape[0],1)\n",
    "    trt_decoder0 = torch.jit.load(\"/dev/shm/decoder0.ts\")\n",
    "    decoder_state, attention_state = trt_decoder0(attention_mask, encoder_state, attention_state, prev_tokens, token_index_batched, token_mask, self_attn_mask)\n",
    "    del trt_decoder0\n",
    "    break\n",
    "    trt_decoder1 = torch.jit.load(\"/dev/shm/decoder1.ts\")\n",
    "    decoder_state, attention_state = trt_decoder1(attention_mask, encoder_state, decoder_state.half(), attention_state.half(), token_index_batched, token_mask, self_attn_mask)\n",
    "    del trt_decoder1\n",
    "    trt_decoder2 = torch.jit.load(\"/dev/shm/decoder2.ts\")\n",
    "    logits, attention_state = trt_decoder2(attention_mask, encoder_state, decoder_state.half(), attention_state.half(), token_index_batched, token_mask, self_attn_mask)\n",
    "    del trt_decoder2\n",
    "    \n",
    "    temperature = settings[[0]]\n",
    "    top_k = settings[[1]].to(torch.long)\n",
    "    supercondition_factor = settings[[2]]\n",
    "    logits = logits[:, -1, : 2 ** 14]\n",
    "    logits = (\n",
    "        logits[:image_count] * (1 - supercondition_factor) + \n",
    "        logits[image_count:] * supercondition_factor\n",
    "    )\n",
    "    logits_sorted, _ = logits.sort(descending=True)\n",
    "    is_kept = (logits >= logits_sorted[:, top_k - 1]).to(decoder_state.dtype)\n",
    "    logits -= logits_sorted[:, [0]]\n",
    "    logits /= temperature\n",
    "    logits.exp_()\n",
    "    logits *= is_kept\n",
    "    image_tokens[i + 1] = torch.multinomial(logits, 1)[:, 0]\n",
    "\n",
    "# with torch.cuda.amp.autocast(dtype=torch.float32) and torch.no_grad():\n",
    "#     detokenizer = VQGanDetokenizer()\n",
    "#     detokenizer.load_state_dict(torch.load('models/detoker.pt'))\n",
    "#     detokenizer = detokenizer.cuda().eval()\n",
    "#     images = detokenizer.forward(image_tokens[1:].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "grid = torchvision.utils.make_grid(images.cpu().detach().movedim(-2, -1).movedim(-3, -2), nrow=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as plt\n",
    "plt.figure(figsize=(16,16))\n",
    "plt.imshow(grid.movedim(0, -1) / 255.)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
